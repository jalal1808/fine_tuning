{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-11T07:33:19.073095Z",
     "iopub.status.busy": "2025-12-11T07:33:19.072320Z",
     "iopub.status.idle": "2025-12-11T07:33:19.078456Z",
     "shell.execute_reply": "2025-12-11T07:33:19.076945Z",
     "shell.execute_reply.started": "2025-12-11T07:33:19.073042Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSeq2SeqLM,\n",
    "    Seq2SeqTrainingArguments,\n",
    "    Seq2SeqTrainer,\n",
    "    DataCollatorForSeq2Seq\n",
    ")\n",
    "from datasets import load_dataset\n",
    "from pypdf import PdfReader\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-11T07:33:44.471284Z",
     "iopub.status.busy": "2025-12-11T07:33:44.470912Z",
     "iopub.status.idle": "2025-12-11T07:33:44.477430Z",
     "shell.execute_reply": "2025-12-11T07:33:44.476473Z",
     "shell.execute_reply.started": "2025-12-11T07:33:44.471263Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def extract_pdf(path):\n",
    "    \"\"\"Extracts text from a PDF file.\"\"\"\n",
    "    reader = PdfReader(path)\n",
    "    text = \"\"\n",
    "    for page in reader.pages:\n",
    "        page_text = page.extract_text()\n",
    "        if page_text:\n",
    "            text += page_text + \"\\n\"\n",
    "    return text\n",
    "\n",
    "def chunk_text(text, max_tokens=400):\n",
    "    \"\"\"Chunks text into segments of approximately max_tokens (words).\"\"\"\n",
    "    words = text.split()\n",
    "    chunks = []\n",
    "    current = []\n",
    "    \n",
    "    overlap = 50 \n",
    "    \n",
    "    for i, w in enumerate(words):\n",
    "        current.append(w)\n",
    "        if len(current) >= max_tokens:\n",
    "            chunks.append(\" \".join(current))\n",
    "            current = words[i - (max_tokens - overlap - 1): i + 1]\n",
    "    \n",
    "    if current and len(\" \".join(current).split()) < max_tokens:\n",
    "        chunks.append(\" \".join(current))\n",
    "        \n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-11T07:33:47.947012Z",
     "iopub.status.busy": "2025-12-11T07:33:47.946313Z",
     "iopub.status.idle": "2025-12-11T07:33:49.620333Z",
     "shell.execute_reply": "2025-12-11T07:33:49.619516Z",
     "shell.execute_reply.started": "2025-12-11T07:33:47.946978Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "pdf_path = \"/kaggle/input/tunerpdf/Behavioural entrepreneurial mindset.pdf\"\n",
    "try:\n",
    "    pdf_text = extract_pdf(pdf_path)\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: PDF not found at {pdf_path}. Please check the path.\")\n",
    "    pdf_text = \"Placeholder text for a document about an entrepreneurial mindset. It discusses core behavioral traits and how they affect business outcomes.\"\n",
    "    \n",
    "chunks = chunk_text(pdf_text)\n",
    "\n",
    "qa_dataset = []\n",
    "\n",
    "for ch in chunks:\n",
    "    instruction = \"Answer the question based on the context.\"\n",
    "    question = \"What is the main topic of this passage?\"\n",
    "    answer = \" \".join(ch.split()[:50])\n",
    "\n",
    "    qa_dataset.append({\n",
    "        \"instruction\": instruction,\n",
    "        \"context\": ch,\n",
    "        \"question\": question,\n",
    "        \"answer\": answer \n",
    "    })\n",
    "\n",
    "jsonl_file = \"train_qa.jsonl\"\n",
    "with open(jsonl_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    for item in qa_dataset:\n",
    "        f.write(json.dumps(item, ensure_ascii=False) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-11T07:34:05.848954Z",
     "iopub.status.busy": "2025-12-11T07:34:05.848683Z",
     "iopub.status.idle": "2025-12-11T07:34:09.187928Z",
     "shell.execute_reply": "2025-12-11T07:34:09.187077Z",
     "shell.execute_reply.started": "2025-12-11T07:34:05.848935Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model_name = \"google/flan-t5-small\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "\n",
    "MAX_INPUT_LENGTH = 512\n",
    "MAX_TARGET_LENGTH = 128\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-11T07:34:12.032397Z",
     "iopub.status.busy": "2025-12-11T07:34:12.031695Z",
     "iopub.status.idle": "2025-12-11T07:34:12.662993Z",
     "shell.execute_reply": "2025-12-11T07:34:12.662091Z",
     "shell.execute_reply.started": "2025-12-11T07:34:12.032368Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "raw_dataset = load_dataset(\"json\", data_files={\"train\": jsonl_file})\n",
    "\n",
    "dataset_dict = raw_dataset[\"train\"].train_test_split(test_size=0.1, seed=42)\n",
    "print(dataset_dict.keys()) \n",
    "\n",
    "def tokenize_function(examples):\n",
    "    prompts = [\n",
    "        f\"### Instruction:\\n{inst}\\n\\n### Context:\\n{ctx}\\n\\n### Question:\\n{q}\\n\\n### Answer: (Must be a concise summary of the key idea)\"\n",
    "        # Note the added explicit instruction at the end\n",
    "        for inst, ctx, q in zip(examples['instruction'], examples['context'], examples['question'])\n",
    "    ]\n",
    "    \n",
    "    model_inputs = tokenizer(\n",
    "        prompts, \n",
    "        max_length=MAX_INPUT_LENGTH, \n",
    "        padding=\"max_length\", \n",
    "        truncation=True,\n",
    "        return_tensors=None \n",
    "    )\n",
    "\n",
    "    labels = tokenizer(\n",
    "        examples['answer'], \n",
    "        max_length=MAX_TARGET_LENGTH, \n",
    "        padding=\"max_length\", \n",
    "        truncation=True,\n",
    "        return_tensors=None\n",
    "    )\n",
    "    \n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    \n",
    "    return model_inputs\n",
    "\n",
    "tokenized_dataset = dataset_dict.map(\n",
    "    tokenize_function, \n",
    "    batched=True,\n",
    "    remove_columns=['instruction', 'context', 'question', 'answer'] # Clean up columns\n",
    ")\n",
    "print(tokenized_dataset.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-11T07:43:02.204979Z",
     "iopub.status.busy": "2025-12-11T07:43:02.204250Z",
     "iopub.status.idle": "2025-12-11T07:43:02.238406Z",
     "shell.execute_reply": "2025-12-11T07:43:02.237717Z",
     "shell.execute_reply.started": "2025-12-11T07:43:02.204954Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"./results_qa\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    # save_steps=50,\n",
    "    # eval_steps=50,\n",
    "    logging_steps=5,\n",
    "    learning_rate=3e-5,\n",
    "    per_device_train_batch_size=4, \n",
    "    per_device_eval_batch_size=4,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=2,\n",
    "    num_train_epochs=20,\n",
    "    predict_with_generate=True,\n",
    "    fp16=True,\n",
    "    generation_max_length=250,\n",
    "    \n",
    "    report_to=\"none\" \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-11T07:43:06.470926Z",
     "iopub.status.busy": "2025-12-11T07:43:06.470192Z",
     "iopub.status.idle": "2025-12-11T07:43:06.475226Z",
     "shell.execute_reply": "2025-12-11T07:43:06.474341Z",
     "shell.execute_reply.started": "2025-12-11T07:43:06.470900Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForSeq2Seq(\n",
    "    tokenizer, \n",
    "    model=model,\n",
    "    padding=True \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-11T07:43:10.998098Z",
     "iopub.status.busy": "2025-12-11T07:43:10.997789Z",
     "iopub.status.idle": "2025-12-11T07:47:07.859801Z",
     "shell.execute_reply": "2025-12-11T07:47:07.858802Z",
     "shell.execute_reply.started": "2025-12-11T07:43:10.998074Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='640' max='640' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [640/640 03:53, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>8.574600</td>\n",
       "      <td>6.179919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4.313000</td>\n",
       "      <td>3.233747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.692900</td>\n",
       "      <td>1.915238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.705700</td>\n",
       "      <td>1.469612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.654000</td>\n",
       "      <td>1.231827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.272000</td>\n",
       "      <td>1.070309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.199400</td>\n",
       "      <td>0.974144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.059300</td>\n",
       "      <td>0.883781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.027000</td>\n",
       "      <td>0.802639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.905700</td>\n",
       "      <td>0.727466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.873600</td>\n",
       "      <td>0.663431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.831700</td>\n",
       "      <td>0.605850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.728500</td>\n",
       "      <td>0.561463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.723800</td>\n",
       "      <td>0.521390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.649000</td>\n",
       "      <td>0.493719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.604300</td>\n",
       "      <td>0.466777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.665300</td>\n",
       "      <td>0.448076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.597900</td>\n",
       "      <td>0.434528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.609400</td>\n",
       "      <td>0.425897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.608400</td>\n",
       "      <td>0.423156</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete.\n"
     ]
    }
   ],
   "source": [
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"test\"],\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "print(\"Starting training...\")\n",
    "trainer.train()\n",
    "print(\"Training complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-11T07:48:53.786098Z",
     "iopub.status.busy": "2025-12-11T07:48:53.785763Z",
     "iopub.status.idle": "2025-12-11T07:48:55.707041Z",
     "shell.execute_reply": "2025-12-11T07:48:55.706233Z",
     "shell.execute_reply.started": "2025-12-11T07:48:53.786075Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query Result:\n",
      "Behavioural entrepreneurial mindset: How entrepreneurial education activity impacts entrepreneurial intention and behaviour Jun Cui & Robin Bell The International Journal of Management Education (2022), 20(2), 100639. Abstract This research investigates how entrepreneurial education activity (EEA) influences entrepreneurial behaviour (EB) by unpacking how EEA influences both entrepreneurial intention (EI) and EB and how behavioural entrepreneurial mindset (BEM) mediates the relationship between EEA and EI. This furthers research into the behavioural subdimension of entrepreneurial mindset and how this impacts the relationship between EEA and EI. Confirm\n"
     ]
    }
   ],
   "source": [
    "test_text = (\n",
    "    f\"### Instruction:\\nAnswer the question based on the context.\\n\\n\"\n",
    "    f\"### Context:\\n{chunks[0]}\\n\\n\"\n",
    "    f\"### Question:\\nWhat is the main gist of the document ?n\\n### Answer:\"\n",
    ")\n",
    "\n",
    "inputs = tokenizer(test_text, return_tensors=\"pt\", truncation=True, padding=\"max_length\", max_length=MAX_INPUT_LENGTH).to(model.device)\n",
    "outputs = model.generate(**inputs, max_new_tokens=MAX_TARGET_LENGTH)\n",
    "print(\"\\nQuery Result:\")\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 8968349,
     "sourceId": 14085970,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31192,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
